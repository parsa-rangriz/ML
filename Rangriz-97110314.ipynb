{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idb7WcKi7VCo"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wYdI8HW86AbB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = list()\n",
    "for i in range(33, 127):\n",
    "    keyword.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKifFdM9_AmD"
   },
   "source": [
    "# Personal Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "WRRiCftV_G5O",
    "outputId": "22a43537-b0dd-4231-852f-ce2b2154b717"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = ['first_name', 'last_name', 'age', 'birth_year', 'country', 'state',\n",
    "          'city', 'address', 'highschool', 'university', 'phone', 'father',\n",
    "          'mother', 'email', 'username', 'zipcode', 'credit_card']\n",
    "\n",
    "data = [\n",
    "        {\n",
    "         'first_name': 'Tonya',\n",
    "         'last_name': 'Watkins',\n",
    "         'age': '31',\n",
    "         'birth_year': '1990',\n",
    "         'country': 'USA',\n",
    "         'state': 'LA',\n",
    "         'city': 'Lake Charles',\n",
    "         'address': '2003 Willow Oaks Lane',\n",
    "         'highschool': 'Lowell High School',\n",
    "         'university': 'UC Irvine',\n",
    "         'phone': '337-338-6860',\n",
    "         'father': 'Thomas',\n",
    "         'mother': 'Jane',\n",
    "         'email': 'TonyaFWatkins@gmail.com',\n",
    "         'username': 'Wiffor1990',\n",
    "         'zipcode': '70601',\n",
    "         'credit_card': '5330 2256 5617 0654'\n",
    "        }\n",
    "]\n",
    "\n",
    "\n",
    "with open('personal_information.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DHZ4n8y8d6l"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI86YkPY8w3W"
   },
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8KvlGU_a8ozt"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    a = sigmoid(x) #1 / (1 + np.exp(-x))\n",
    "    return a*(1-a) \n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "## Input cannot be a list, it has to be either a number or a numpy array. \n",
    "def d_relu(x):\n",
    "    return x>0\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return np.maximum(0.01*x ,x)\n",
    "\n",
    "## Input cannot be a list, it has to be either a number or a numpy array. \n",
    "def d_leaky_relu(x):\n",
    "    return (x>0) + .01*(x<0)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1-np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV9lNt73821G"
   },
   "source": [
    "## Random Network Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IsQUu7f88cu1"
   },
   "outputs": [],
   "source": [
    "def random_network_generator( nl_list ):\n",
    "    w_list = []\n",
    "    b_list = []\n",
    "    for i in range(len(nl_list)-1 ):\n",
    "        w_list += [ np.random.uniform(-1,1,size=[nl_list[i+1] , nl_list[i] ]) ]\n",
    "        b_list += [ np.random.uniform(-1,1,size=[ nl_list[i+1], 1 ]) ]\n",
    "    return w_list, b_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D438fJ4r9END"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSS(a):\n",
    "    information = pd.read_csv('personal_information.csv')\n",
    "    information = information.values[0]\n",
    "    distance = 0\n",
    "    S = str()\n",
    "    for i in range(len(a[0])):\n",
    "        a[0][i] = (a[0][i] - min(a[0])) / (max(a[0]) - min(a[0])) * (max(keyword) - min(keyword)) + min(keyword)\n",
    "        S = S + (chr(int(a[0][i]*len(keyword) + min(keyword))))\n",
    "    for feature in range(len(information)):  \n",
    "        distance -= int(str(information[feature]).lower() in S.lower())\n",
    "    for i in range(len(Y)):\n",
    "        for j in range(len(Y)):\n",
    "            if i != j and Y.lower()[i] == Y.lower()[j]:\n",
    "                distance -= 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCOrA8au9ojP"
   },
   "source": [
    "## Feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer(x, w, b ,  activation_func=(lambda x: leaky_relu(x)  ) ):\n",
    "    z = np.dot( w, x) + b\n",
    "    return z , activation_func( z )\n",
    "\n",
    "def NN_forward(x, w_list, b_list, activation_func_list=[(lambda x: leaky_relu(x))]  ):\n",
    "    a = x\n",
    "    z_list = []\n",
    "    a_list = [a]\n",
    "    if len(activation_func_list) == 1: \n",
    "        for i in range(len(w_list)):\n",
    "            z, a = single_layer(a , w_list[i], b_list[i] , activation_func_list[0] )\n",
    "            z_list += [ z ]\n",
    "            a_list += [ a ]\n",
    "    else:                           \n",
    "        for i in range(len(w_list)):\n",
    "            z, a = single_layer(a , w_list[i], b_list[i] , activation_func_list[i] )\n",
    "            z_list += [ z ]\n",
    "            a_list += [ a ]\n",
    "      \n",
    "    return a_list, z_list\n",
    "  \n",
    "\n",
    "def NN_func(w_list, b_list,  activation_func_list=[(lambda x: leaky_relu(x)) ] ):\n",
    "    def func(x):\n",
    "        return NN_forward(x, w_list, b_list, activation_func_list)\n",
    "    return(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_list = [len(keyword), 10, 1]\n",
    "ws, bs = random_network_generator(nl_list)\n",
    "\n",
    "nn_f = NN_func(ws, bs , activation_func_list=[(lambda x: leaky_relu(x) )] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Generation (v.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first password is: \u0001\u0001_\f",
      "\u0001\b\u0001\u0001\u0001\u0010\n"
     ]
    }
   ],
   "source": [
    "X = keyword\n",
    "for i in range(len(keyword)):\n",
    "    X[i] = (X[i] - min(X)) / (max(X) - min(X))\n",
    "Z = nn_f(X)\n",
    "output = Z[0][-1]\n",
    "Y = str()\n",
    "for i in range(len(output[0])):\n",
    "    output[0][i] = (output[0][i] - min(output[0])) / (max(output[0]) - min(output[0])) * (max(X) - min(X)) + min(X)\n",
    "    output[0][i] = int(output[0][i]*len(keyword) + min(keyword) + 1)\n",
    "    Y = Y + (chr(int(output[0][i])))\n",
    "print('Our first password is:',Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-forward & Back-propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    \n",
    "    def __init__(self, nl_list, \n",
    "                 activation_func_list= [[ lambda x: sigmoid(x), lambda x:sigmoid(x)*(1-sigmoid(x)) ] ], \n",
    "                 loss = [LOSS, LOSS],\n",
    "                 n_itr = 1000, ETA = .01, return_hist = False, \n",
    "                 return_loss_hist = False):\n",
    "\n",
    "        self.trained_ = False  \n",
    "        \n",
    "        self.n_f = nl_list[0]  \n",
    "        self.n_l_list = nl_list\n",
    "        self.n_layers = len(nl_list)\n",
    "        print(f\"There are {self.n_layers} layers in this network.\")\n",
    "               \n",
    "        self.w_list_, self.b_list_ = random_network_generator(self.n_l_list)\n",
    "        \n",
    "        self.loss_func = loss\n",
    "        if not len(activation_func_list) == self.n_layers-1:\n",
    "            print('Not enough act_func, will use the first layer for all of them.')\n",
    "            self.activation_func_list = np.array([activation_func_list[0] for i in range(self.n_layers-1) ])\n",
    "        else:\n",
    "            self.activation_func_list = np.array(activation_func_list)\n",
    "        \n",
    "        self.ETA = ETA   \n",
    "        self.n_itr = n_itr  \n",
    "        \n",
    "        self.return_hist = return_hist  \n",
    "        self.return_loss = return_loss_hist \n",
    "        \n",
    "        self.a_list = []\n",
    "        self.z_list = []\n",
    "        \n",
    "        self.loss_hist = []\n",
    "        self.w_hist = []\n",
    "        self.b_hist = []\n",
    "        self.Y_pred_hist = []\n",
    "\n",
    "    def single_step_forward(self, x, w, b ,  activation_func):\n",
    "        z = np.dot( w, x) + b\n",
    "        return z , activation_func( z ) \n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.trained_: \n",
    "            a = X\n",
    "            \n",
    "            self.z_list = []\n",
    "            self.a_list = [a]\n",
    "            if len(self.activation_func_list) == 1:  \n",
    "                for i in range(len(self.w_list_)):\n",
    "                                        \n",
    "                    z, a = self.single_step_forward( x=self.a_list[-1], \n",
    "                                                    w = self.w_list_[i], \n",
    "                                                    b=self.b_list_[i],\n",
    "                                                   activation_func = self.activation_func_list[0, 0])\n",
    "                    self.z_list += [ z ]\n",
    "                    self.a_list += [ a ]\n",
    "                    \n",
    "            else:                            \n",
    "                for i in range(len(self.w_list_)):\n",
    "\n",
    "                    z, a = self.single_step_forward(a , self.w_list_[i], \n",
    "                                                    self.b_list_[i] , \n",
    "                                                    self.activation_func_list[i][0] )\n",
    "                    self.z_list += [ z ]\n",
    "                    self.a_list += [ a ]\n",
    "\n",
    "            return a\n",
    "\n",
    "        else:\n",
    "            print(\"Not trained yet. \")\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        self.trained_= True  \n",
    "        self.n_f , n_s = X.shape        \n",
    "        loss_list = []\n",
    "        w_list_list = []\n",
    "        b_list_list = []\n",
    "\n",
    "        for m in range(self.n_itr):\n",
    "      \n",
    "            layer_ind = self.n_layers - 1\n",
    "            a = self.predict( X )\n",
    "#             print(a)\n",
    "            self.Y_pred_hist += [ a ]\n",
    "\n",
    "\n",
    "            loss_list += [ self.loss_func[0](a) ]\n",
    "            w_list_list += [self.w_list_.copy()]\n",
    "            b_list_list += [self.b_list_.copy()]\n",
    "\n",
    "            da = self.loss_func[1](a)\n",
    "\n",
    "            dz = da * self.activation_func_list[layer_ind-1 , 1](self.z_list[layer_ind-1]) \n",
    "\n",
    "            dw = np.dot(  dz, self.a_list[layer_ind-1].T  ).reshape(self.n_l_list[layer_ind], \n",
    "                                                                    self.n_l_list[layer_ind-1])/n_s\n",
    "            db = np.sum(dz, axis=1).reshape(self.n_l_list[layer_ind],1)/n_s\n",
    "            dw_list = [dw]\n",
    "            db_list = [db]\n",
    "            for i in range(1, len(self.n_l_list)-1):\n",
    "                layer_ind =  self.n_layers-i-1\n",
    "                a = self.a_list[layer_ind]\n",
    "                w = self.w_list_[layer_ind]\n",
    "\n",
    "                dz = np.dot( w.T, dz ) * self.activation_func_list[layer_ind-1 , 1](self.z_list[layer_ind-1])     \n",
    "                dw = np.dot(  dz, self.a_list[layer_ind-1].T  ).reshape(self.n_l_list[layer_ind], \n",
    "                                                                        self.n_l_list[layer_ind-1])/n_s\n",
    "                db = np.sum(dz, axis=1).reshape(self.n_l_list[layer_ind],1)/n_s\n",
    "                dw_list += [dw]\n",
    "                db_list += [db]\n",
    "            \n",
    "\n",
    "            dw_list = dw_list[::-1]\n",
    "            db_list = db_list[::-1]\n",
    "            self.w_list_ = [self.w_list_[ind] - self.ETA*dw_list[ind] for ind in range(self.n_layers-1)]\n",
    "            self.b_list_ = [self.b_list_[ind] - self.ETA*db_list[ind] for ind in range(self.n_layers-1)]\n",
    "            \n",
    "        \n",
    "        a = self.predict( X )\n",
    "\n",
    "        loss_list += [self.loss_func[0](a) ]\n",
    "        w_list_list += [self.w_list_.copy()]\n",
    "        b_list_list += [self.b_list_.copy()]\n",
    "            \n",
    "        self.loss_hist += loss_list\n",
    "        self.w_hist += [w_list_list]\n",
    "        self.b_hist += [b_list_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Generation (v.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keyword\n",
    "for i in range(len(keyword)):\n",
    "    X[i] = (X[i] - min(X)) / (max(X) - min(X))  \n",
    "X = np.array([X,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 layers in this network.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nl_list = [1, 10 , 1]\n",
    "act_list = [ [leaky_relu, leaky_relu] , [leaky_relu, leaky_relu] ]\n",
    "model = NN(nl_list, n_itr=5, ETA = .1, activation_func_list=act_list)\n",
    "model.fit(X)\n",
    "plt.plot(model.loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12605753e+130, 4.87627327e+130, 4.89833844e+130,\n",
       "        4.92040361e+130, 4.94246878e+130, 4.96453394e+130,\n",
       "        4.98659911e+130, 5.00866428e+130, 5.03072945e+130,\n",
       "        5.05279462e+130, 5.07485979e+130, 5.09692496e+130,\n",
       "        5.11899013e+130, 5.14105529e+130, 5.16312046e+130,\n",
       "        5.18518563e+130, 5.20725080e+130, 5.22931597e+130,\n",
       "        5.25138114e+130, 5.27344631e+130, 5.29551148e+130,\n",
       "        5.31757664e+130, 5.33964181e+130, 5.36170698e+130,\n",
       "        5.38377215e+130, 5.40583732e+130, 5.42790249e+130,\n",
       "        5.44996766e+130, 5.47203283e+130, 5.49409799e+130,\n",
       "        5.51616316e+130, 5.53822833e+130, 5.56029350e+130,\n",
       "        5.58235867e+130, 5.60442384e+130, 5.62648901e+130,\n",
       "        5.64855417e+130, 5.67061934e+130, 5.69268451e+130,\n",
       "        5.71474968e+130, 5.73681485e+130, 5.75888002e+130,\n",
       "        5.78094519e+130, 5.80301036e+130, 5.82507552e+130,\n",
       "        5.84714069e+130, 5.86920586e+130, 5.89127103e+130,\n",
       "        5.91333620e+130, 5.93540137e+130, 5.95746654e+130,\n",
       "        5.97953171e+130, 6.00159687e+130, 6.02366204e+130,\n",
       "        6.04572721e+130, 6.06779238e+130, 6.08985755e+130,\n",
       "        6.11192272e+130, 6.13398789e+130, 6.15605305e+130,\n",
       "        6.17811822e+130, 6.20018339e+130, 6.22224856e+130,\n",
       "        6.24431373e+130, 6.26637890e+130, 6.28844407e+130,\n",
       "        6.31050924e+130, 6.33257440e+130, 6.35463957e+130,\n",
       "        6.37670474e+130, 6.39876991e+130, 6.42083508e+130,\n",
       "        6.44290025e+130, 6.46496542e+130, 6.48703059e+130,\n",
       "        6.50909575e+130, 6.53116092e+130, 6.55322609e+130,\n",
       "        6.57529126e+130, 6.59735643e+130, 6.61942160e+130,\n",
       "        6.64148677e+130, 6.66355193e+130, 6.68561710e+130,\n",
       "        6.70768227e+130, 6.72974744e+130, 6.75181261e+130,\n",
       "        6.77387778e+130, 6.79594295e+130, 6.81800812e+130,\n",
       "        6.84007328e+130, 6.86213845e+130, 6.88420362e+130,\n",
       "        6.90626879e+130]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 94)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = model.predict(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keyword\n",
    "for i in range(len(keyword)):\n",
    "    X[i] = (X[i] - min(X)) / (max(X) - min(X))\n",
    "output = Y[0]\n",
    "S = str()\n",
    "for i in range(len(Y)):\n",
    "    Y[0][i] = (Y[0][i] - min(Y[0])) / (max(Y[0]) - min(Y[0])) * (max(keyword) - min(keyword)) + min(keyword)\n",
    "    S = S + (chr(int(Y[0][i]*len(keyword) + min(keyword))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Rangriz - 97110314.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
