{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idb7WcKi7VCo"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wYdI8HW86AbB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = list()\n",
    "for i in range(33, 127):\n",
    "    keyword.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKifFdM9_AmD"
   },
   "source": [
    "# Personal Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "WRRiCftV_G5O",
    "outputId": "22a43537-b0dd-4231-852f-ce2b2154b717"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = ['first_name', 'last_name', 'age', 'birth_year', 'country', 'state',\n",
    "          'city', 'address', 'highschool', 'university', 'phone', 'father',\n",
    "          'mother', 'email', 'username', 'zipcode', 'credit_card']\n",
    "\n",
    "data = [\n",
    "        {\n",
    "         'first_name': 'Tonya',\n",
    "         'last_name': 'Watkins',\n",
    "         'age': '31',\n",
    "         'birth_year': '1990',\n",
    "         'country': 'USA',\n",
    "         'state': 'LA',\n",
    "         'city': 'Lake Charles',\n",
    "         'address': '2003 Willow Oaks Lane',\n",
    "         'highschool': 'Lowell High School',\n",
    "         'university': 'UC Irvine',\n",
    "         'phone': '337-338-6860',\n",
    "         'father': 'Thomas',\n",
    "         'mother': 'Jane',\n",
    "         'email': 'TonyaFWatkins@gmail.com',\n",
    "         'username': 'Wiffor1990',\n",
    "         'zipcode': '70601',\n",
    "         'credit_card': '5330 2256 5617 0654'\n",
    "        }\n",
    "]\n",
    "\n",
    "\n",
    "with open('personal_information.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DHZ4n8y8d6l"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI86YkPY8w3W"
   },
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8KvlGU_a8ozt"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    a = sigmoid(x) #1 / (1 + np.exp(-x))\n",
    "    return a*(1-a) \n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "## Input cannot be a list, it has to be either a number or a numpy array. \n",
    "def d_relu(x):\n",
    "    return x>0\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return np.maximum(0.01*x ,x)\n",
    "\n",
    "## Input cannot be a list, it has to be either a number or a numpy array. \n",
    "def d_leaky_relu(x):\n",
    "    return (x>0) + .01*(x<0)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1-np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV9lNt73821G"
   },
   "source": [
    "## Random Network Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IsQUu7f88cu1"
   },
   "outputs": [],
   "source": [
    "def random_network_generator( nl_list ):\n",
    "    w_list = []\n",
    "    b_list = []\n",
    "    for i in range(len(nl_list)-1 ):\n",
    "        w_list += [ np.random.uniform(-1,1,size=[nl_list[i+1] , nl_list[i] ]) ]\n",
    "        b_list += [ np.random.uniform(-1,1,size=[ nl_list[i+1], 1 ]) ]\n",
    "    return w_list, b_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D438fJ4r9END"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSS(a):\n",
    "    information = pd.read_csv('personal_information.csv')\n",
    "    information = information.values[0]\n",
    "    distance = 0\n",
    "    S = str()\n",
    "    for i in range(len(a[0])):\n",
    "        a[0][i] = (a[0][i] - min(a[0])) / (max(a[0]) - min(a[0])) * (max(keyword) - min(keyword)) + min(keyword)\n",
    "        S = S + (chr(int(a[0][i]*len(keyword) + min(keyword))))\n",
    "    for feature in range(len(information)):  \n",
    "        distance -= int(str(information[feature]).lower() in S.lower())\n",
    "    for i in range(len(Y)):\n",
    "        for j in range(len(Y)):\n",
    "            if i != j and Y.lower()[i] == Y.lower()[j]:\n",
    "                distance -= 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCOrA8au9ojP"
   },
   "source": [
    "## Feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer(x, w, b ,  activation_func=(lambda x: leaky_relu(x)  ) ):\n",
    "    z = np.dot( w, x) + b\n",
    "    return z , activation_func( z )\n",
    "\n",
    "def NN_forward(x, w_list, b_list, activation_func_list=[(lambda x: leaky_relu(x))]  ):\n",
    "    a = x\n",
    "    z_list = []\n",
    "    a_list = [a]\n",
    "    if len(activation_func_list) == 1: \n",
    "        for i in range(len(w_list)):\n",
    "            z, a = single_layer(a , w_list[i], b_list[i] , activation_func_list[0] )\n",
    "            z_list += [ z ]\n",
    "            a_list += [ a ]\n",
    "    else:                           \n",
    "        for i in range(len(w_list)):\n",
    "            z, a = single_layer(a , w_list[i], b_list[i] , activation_func_list[i] )\n",
    "            z_list += [ z ]\n",
    "            a_list += [ a ]\n",
    "      \n",
    "    return a_list, z_list\n",
    "  \n",
    "\n",
    "def NN_func(w_list, b_list,  activation_func_list=[(lambda x: leaky_relu(x)) ] ):\n",
    "    def func(x):\n",
    "        return NN_forward(x, w_list, b_list, activation_func_list)\n",
    "    return(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_list = [len(keyword), 10, 1]\n",
    "ws, bs = random_network_generator(nl_list)\n",
    "\n",
    "nn_f = NN_func(ws, bs , activation_func_list=[(lambda x: leaky_relu(x) )] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Generation (v.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first password is: _\u0002\u0001\u0002\u0002\u0001\u0003\u0003\u0001\u0001\n"
     ]
    }
   ],
   "source": [
    "X = keyword\n",
    "for i in range(len(keyword)):\n",
    "    X[i] = (X[i] - min(X)) / (max(X) - min(X))\n",
    "Z = nn_f(X)\n",
    "output = Z[0][-1]\n",
    "Y = str()\n",
    "for i in range(len(output[0])):\n",
    "    output[0][i] = (output[0][i] - min(output[0])) / (max(output[0]) - min(output[0])) * (max(X) - min(X)) + min(X)\n",
    "    output[0][i] = int(output[0][i]*len(keyword) + min(keyword) + 1)\n",
    "    Y = Y + (chr(int(output[0][i])))\n",
    "print('Our first password is:',Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-forward & Back-propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    \n",
    "    def __init__(self, nl_list, \n",
    "                 activation_func_list= [[ lambda x: sigmoid(x), lambda x:sigmoid(x)*(1-sigmoid(x)) ] ], \n",
    "                 loss = [LOSS, LOSS],\n",
    "                 n_itr = 1000, ETA = .01, return_hist = False, \n",
    "                 return_loss_hist = False):\n",
    "\n",
    "        self.trained_ = False  \n",
    "        \n",
    "        self.n_f = nl_list[0]  \n",
    "        self.n_l_list = nl_list\n",
    "        self.n_layers = len(nl_list)\n",
    "        print(f\"There are {self.n_layers} layers in this network.\")\n",
    "               \n",
    "        self.w_list_, self.b_list_ = random_network_generator(self.n_l_list)\n",
    "        \n",
    "        self.loss_func = loss\n",
    "        if not len(activation_func_list) == self.n_layers-1:\n",
    "            print('Not enough act_func, will use the first layer for all of them.')\n",
    "            self.activation_func_list = np.array([activation_func_list[0] for i in range(self.n_layers-1) ])\n",
    "        else:\n",
    "            self.activation_func_list = np.array(activation_func_list)\n",
    "        \n",
    "        self.ETA = ETA   \n",
    "        self.n_itr = n_itr  \n",
    "        \n",
    "        self.return_hist = return_hist  \n",
    "        self.return_loss = return_loss_hist \n",
    "        \n",
    "        self.a_list = []\n",
    "        self.z_list = []\n",
    "        \n",
    "        self.loss_hist = []\n",
    "        self.w_hist = []\n",
    "        self.b_hist = []\n",
    "        self.Y_pred_hist = []\n",
    "\n",
    "    def single_step_forward(self, x, w, b ,  activation_func):\n",
    "        z = np.dot( w, x) + b\n",
    "        return z , activation_func( z ) \n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.trained_: \n",
    "            a = X\n",
    "            \n",
    "            self.z_list = []\n",
    "            self.a_list = [a]\n",
    "            if len(self.activation_func_list) == 1:  \n",
    "                for i in range(len(self.w_list_)):\n",
    "                                        \n",
    "                    z, a = self.single_step_forward( x=self.a_list[-1], \n",
    "                                                    w = self.w_list_[i], \n",
    "                                                    b=self.b_list_[i],\n",
    "                                                   activation_func = self.activation_func_list[0, 0])\n",
    "                    self.z_list += [ z ]\n",
    "                    self.a_list += [ a ]\n",
    "                    \n",
    "            else:                            \n",
    "                for i in range(len(self.w_list_)):\n",
    "\n",
    "                    z, a = self.single_step_forward(a , self.w_list_[i], \n",
    "                                                    self.b_list_[i] , \n",
    "                                                    self.activation_func_list[i][0] )\n",
    "                    self.z_list += [ z ]\n",
    "                    self.a_list += [ a ]\n",
    "\n",
    "            return a\n",
    "\n",
    "        else:\n",
    "            print(\"Not trained yet. \")\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        self.trained_= True  \n",
    "        self.n_f , n_s = X.shape        \n",
    "        loss_list = []\n",
    "        w_list_list = []\n",
    "        b_list_list = []\n",
    "\n",
    "        for m in range(self.n_itr):\n",
    "      \n",
    "            layer_ind = self.n_layers - 1\n",
    "            a = self.predict( X )\n",
    "#             print(a)\n",
    "            self.Y_pred_hist += [ a ]\n",
    "\n",
    "\n",
    "            loss_list += [ self.loss_func[0](a) ]\n",
    "            w_list_list += [self.w_list_.copy()]\n",
    "            b_list_list += [self.b_list_.copy()]\n",
    "\n",
    "            da = self.loss_func[1](a)\n",
    "\n",
    "            dz = da * self.activation_func_list[layer_ind-1 , 1](self.z_list[layer_ind-1]) \n",
    "\n",
    "            dw = np.dot(  dz, self.a_list[layer_ind-1].T  ).reshape(self.n_l_list[layer_ind], \n",
    "                                                                    self.n_l_list[layer_ind-1])/n_s\n",
    "            db = np.sum(dz, axis=1).reshape(self.n_l_list[layer_ind],1)/n_s\n",
    "            dw_list = [dw]\n",
    "            db_list = [db]\n",
    "            for i in range(1, len(self.n_l_list)-1):\n",
    "                layer_ind =  self.n_layers-i-1\n",
    "                a = self.a_list[layer_ind]\n",
    "                w = self.w_list_[layer_ind]\n",
    "\n",
    "                dz = np.dot( w.T, dz ) * self.activation_func_list[layer_ind-1 , 1](self.z_list[layer_ind-1])     \n",
    "                dw = np.dot(  dz, self.a_list[layer_ind-1].T  ).reshape(self.n_l_list[layer_ind], \n",
    "                                                                        self.n_l_list[layer_ind-1])/n_s\n",
    "                db = np.sum(dz, axis=1).reshape(self.n_l_list[layer_ind],1)/n_s\n",
    "                dw_list += [dw]\n",
    "                db_list += [db]\n",
    "            \n",
    "\n",
    "            dw_list = dw_list[::-1]\n",
    "            db_list = db_list[::-1]\n",
    "            self.w_list_ = [self.w_list_[ind] - self.ETA*dw_list[ind] for ind in range(self.n_layers-1)]\n",
    "            self.b_list_ = [self.b_list_[ind] - self.ETA*db_list[ind] for ind in range(self.n_layers-1)]\n",
    "            \n",
    "        \n",
    "        a = self.predict( X )\n",
    "\n",
    "        loss_list += [self.loss_func[0](a) ]\n",
    "        w_list_list += [self.w_list_.copy()]\n",
    "        b_list_list += [self.b_list_.copy()]\n",
    "            \n",
    "        self.loss_hist += loss_list\n",
    "        self.w_hist += [w_list_list]\n",
    "        self.b_hist += [b_list_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Generation (v.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keyword\n",
    "for i in range(len(keyword)):\n",
    "    X[i] = (X[i] - min(X)) / (max(X) - min(X))  \n",
    "X = np.array([X,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 layers in this network.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nl_list = [1, 10 , 1]\n",
    "act_list = [ [sigmoid, sigmoid] , [sigmoid, sigmoid] ]\n",
    "model = NN(nl_list, n_itr=1000, ETA = .1, activation_func_list=act_list)\n",
    "model.fit(X)\n",
    "plt.plot(model.loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^\\x00%%%%%%%%'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = keyword\n",
    "for i in range(len(keyword)):\n",
    "    X[i] = (X[i] - min(X)) / (max(X) - min(X))\n",
    "output = Y[0]\n",
    "S = str()\n",
    "for i in range(len(Y[0])):\n",
    "    Y[0][i] = (Y[0][i] - min(Y[0])) / (max(Y[0]) - min(Y[0])) * (max(keyword) - min(keyword)) + min(keyword)\n",
    "    S = S + (chr(int(Y[0][i]*len(keyword) + min(keyword))))\n",
    "S[:10]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Rangriz - 97110314.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
